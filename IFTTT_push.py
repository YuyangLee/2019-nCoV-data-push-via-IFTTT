# -*- coding: utf-8 -*-
import json
import requests
import pandas as pds
import socket
import datetime

from apscheduler.schedulers.blocking import BlockingScheduler
from apscheduler.triggers.cron import CronTrigger

cur_version = "1.2.0 Alpha"

get_Data_URL = "https://view.inews.qq.com/g2/getOnsInfo"
sub_doc_path = r"subscribed_urls.csv"

post_url_p1 = "https://maker.ifttt.com/trigger/"
post_url_p2 = "/with/key/"
host_name   = socket.gethostname()

CEE_date = datetime.date(2020, 6, 7)    # è¿™ä¸€å­—ç¬¦ä¸²æ˜¯æ¨é€åœ°å€æ•°æ®çš„ csv æ–‡ä»¶åœ°å€
area_requested = ['å®å¤', 'æ¹–åŒ—']        # è¿™ä¸€åˆ—è¡¨åŒ…å«äº†ä½ è®¢é˜…æ•°æ®çš„çœï¼ˆè‡ªæ²»åŒºã€ç›´è¾–å¸‚ï¼‰

def output_log(log_text): print("[", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "] ", log_text)

def get_data():
    output_log("å¼€å¯ä¸€è½®æ¨é€ã€‚\n")
    try:
        global post_urls
        post_urls = read_urls(sub_doc_path)
        output_log("è¯»å–åˆ°" + str(len(post_urls)) + "æ¡è®¢é˜…åœ°å€ã€‚\n")
    except:
        output_log("è®¢é˜…åœ°å€è·å–å¤±è´¥ï¼è¯·æ£€æŸ¥ç¨‹åºï¼\n")
    
    output_log("æ­£è·å–æ•°æ®è‡ª " + get_Data_URL)

    try:
        res = requests.post(get_Data_URL, {"name": "disease_h5"})
        res_timeline = requests.post(get_Data_URL, {"name": "wuwei_ww_time_line"})
        data = json.loads(json.loads(res.text)['data'])
        news = json.loads(json.loads(res_timeline.text)['data'])

        data_dome = data['chinaTotal']
        text_dome = "\\nğŸ‡¨ğŸ‡³å…¨å›½æ•°æ®:\\næˆªæ­¢" + str(data['lastUpdateTime']) + " GMT+8:\\nç¡®è¯Š:" + str(data_dome['confirm']) + "\\tç–‘ä¼¼:" + str(data_dome['suspect']) + "\\næ­»äº¡:" + str(data_dome['dead']) + "\\tæ²»æ„ˆ:" + str(data_dome['heal'])
        text_prov = "\\n"

        text_dome = text_dome + "\\n\\nğŸ“°æœ€æ–°æ¶ˆæ¯:"
        for i in range(2):
            index = len(news) - 1 - i
            text_dome = text_dome + "\\n[" + news[index]['time'] + "]" + news[index]['title']

        data_prov_tree = data['areaTree'][0]['children']
        for area_req in area_requested:
            prov_index = -1
            for i in range(len(data_prov_tree)):
                if data_prov_tree[i]['name'] == area_req:
                    print("\n")
                    output_log("äºç´¢å¼• " + str(i) + " è·å–åˆ°åˆ° " + area_req + "æ•°æ®ã€‚")
                    prov_index = i
                    break
            
            if i >= 0:
                data_prov = data_prov_tree[prov_index]
                text_prov = text_prov + "\\nğŸ™" + area_req + "æ•°æ®:\\nç¡®è¯Š:"
                text_prov = text_prov + str(data_prov['total']['confirm']) + "\\tç–‘ä¼¼:" + str(data_prov['total']['suspect']) + "\\næ­»äº¡:" + str(data_prov['total']['dead']) + "\\t\\tæ²»æ„ˆ:" + str(data_prov['total']['heal']) + "\\næ–°å¢ç¡®è¯Š:" + str(data_prov['today']['confirm']) + "\\næ²»æ„ˆç‡:" + str(data_prov['total']['healRate']) + "\\tæ­»äº¡ç‡:" + str(data_prov['total']['deadRate']) + "\\n"
                if not data_prov['today']['isUpdated']:
                    text_prov = text_prov + "æ³¨ï¼šæ­¤åŸå¸‚æ–°å¢ç¡®è¯Šæ•°æ®æœªæ›´æ–°ã€‚\\n"
                
                for city in data_prov['children']:
                    output_log("æ‰¾åˆ°" + city['name'] + "æ•°æ®ã€‚")
                    text_prov = text_prov + "â–ª" + city['name'] + "æ•°æ®:\\nç¡®è¯Š:" + str(city['total']['confirm']) + "\\t\\tç–‘ä¼¼:" + str(city['total']['suspect']) + "\\næ­»äº¡:" + str(city['total']['dead']) + "\\t\\tæ²»æ„ˆ:" + str(city['total']['heal']) + "\\næ–°å¢ç¡®è¯Š:" + str(city['today']['confirm']) + "\\næ²»æ„ˆç‡:" + str(city['total']['healRate'] + "\\tæ­»äº¡ç‡:" + str(city['total']['deadRate'])) + "\\n"
                    if not city['today']['isUpdated']:
                        text_prov = text_prov + "æ³¨ï¼šæ­¤åŸå¸‚æ–°å¢ç¡®è¯Šæ•°æ®æœªæ›´æ–°ã€‚\\n"

        print("\n")
        output_log("æ•°æ®è·å–æˆåŠŸï¼Œå‡†å¤‡æ¨é€è‡³IFTTTã€‚")
        IFTTT_push(text_dome, text_prov, False)
    except:
        try:
            IFTTT_push("æ•°æ®è·å–å¤±è´¥ã€‚", "è¯·æ‹¨å†—é€šçŸ¥æœåŠ¡è¿è¥è€…ã€‚", True)
            output_log("æ•°æ®è·å–å¤±è´¥ï¼è¯·æ£€æŸ¥ç¨‹åºï¼\n")
        except:
            output_log("æ•°æ®è·å–å¤±è´¥ï¼è¯·æ£€æŸ¥ç½‘è·¯ï¼\n")
    
    output_log("æœ¬è½®æ¨é€ç»“æŸã€‚\n\n")

def IFTTT_push(push_text_1, push_text_2, silent_mode):
    today    = datetime.date.today()
    CEE_left = (CEE_date - today).days

    push_val1_text = "2019-nCoV æ•°æ®æ¨é€\\næ¨é€æ—¶é—´:" + datetime.datetime.now().strftime("%Y-%m-%d %H:%M") + " GMT+8\\næ¨é€è®¾å¤‡:" + host_name + "\\né«˜è€ƒå€’è®¡æ—¶:" + str(CEE_left) + "å¤©\\n\\næ¨é€å†…å®¹:"
    push_val2_text = "\\n" + push_text_1
    push_val3_text = "\\n" + push_text_2 + "\\n"
    body = "{ \"value1\": \"" + push_val1_text + "\", \"value2\": \"" + push_val2_text + "\", \"value3\": \"" + push_val3_text + "\" }"
    headers = { 'Content-Type': 'application/json' }

    try:
        for url in post_urls:
            requests.post(url, data = body.encode('utf-8'), headers = headers)
            if not silent_mode: output_log("å·²å®Œæˆå¯¹" + str(len(post_urls)) + "ä¸ªåœ°å€çš„æ¨é€ã€‚\n")
    except:
        output_log("æ¨é€å¤±è´¥ï¼Œè¯·æ£€æŸ¥è®¾ç½®ï¼\n")

def read_urls(path):
    a = pds.read_csv(path)
    names = a['event_name']
    keys  = a['key']
    urls  = [post_url_p1 + names[i] + post_url_p2 + keys[i] for i in range(len(names))]
    return urls

if __name__ == "__main__":    
    post_urls = read_urls(sub_doc_path)

    IFTTT_push("ç¨‹åºå·²ä¸Šçº¿ã€‚\\nå½“å‰ç‰ˆæœ¬:" + cur_version, "æ¨é€æ¨¡å¼:æ•´ç‚¹æ¨é€ã€‚\\n", True)

    output_log("ç¨‹åºå·²ä¸Šçº¿ã€‚å½“å‰ç‰ˆæœ¬:" + cur_version)
    output_log("å½“å‰è®¾å¤‡ Host Name: " + host_name + "\n")

    output_log("å¼€å§‹è¿è¡Œæ¨é€æœåŠ¡ã€‚æ¨é€æ¨¡å¼:æ•´ç‚¹æ¨é€ã€‚\n")
    get_data()
    scheduler = BlockingScheduler()
    trigger = CronTrigger(hour='*/1')
    scheduler.add_job(get_data,trigger)
    scheduler.start()