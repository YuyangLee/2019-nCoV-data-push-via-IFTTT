# -*- coding: utf-8 -*-
import json
import requests
import pandas as pds
import socket
import datetime

from apscheduler.schedulers.blocking import BlockingScheduler
from apscheduler.triggers.cron import CronTrigger

cur_version = "1.1.0 Alpha"

get_Data_URL = "https://view.inews.qq.com/g2/getOnsInfo"
sub_doc_path = 'subscribed_urls.csv'
t_url = "https://maker.ifttt.com/trigger/program_push/with/key/fP7Zt7dO7IqmDBZI49uEUfagP4rnYK9gD5jTLYmKMRG"

post_url_p1 = "https://maker.ifttt.com/trigger/"
post_url_p2 = "/with/key/"
host_name   = socket.gethostname()
CEE_date = datetime.date(2020, 6, 7)


area_requested = ['å®å¤', 'æ¹–åŒ—']

def output_log(log_text): print("[", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "] ", log_text)

def get_data():
    output_log("å¼€å¯ä¸€è½®æ¨é€ã€‚\n")
    try:
        global post_urls
        post_urls = read_urls(sub_doc_path)
        output_log("è¯»å–åˆ°" + str(len(post_urls)) + "æ¡è®¢é˜…åœ°å€ã€‚\n")
    except:
        output_log("è®¢é˜…åœ°å€è·å–å¤±è´¥ï¼è¯·æ£€æŸ¥ç¨‹åºï¼\n")
    
    output_log("æ­£è·å–æ•°æ®è‡ª " + get_Data_URL)

    try:
        res = requests.post(get_Data_URL, {"name": "disease_h5"})
        res_timeline = requests.post(get_Data_URL, {"name": "wuwei_ww_time_line"})
        data = json.loads(json.loads(res.text)['data'])
        news = json.loads(json.loads(res_timeline.text)['data'])

        data_dome = data['chinaTotal']
        text_dome = "\\nğŸ‡¨ğŸ‡³å…¨å›½æ•°æ®ï¼š\\næˆªæ­¢" + str(data['lastUpdateTime']) + " GMT+8ï¼š\\nç¡®è¯Š:" + str(data_dome['confirm']) + "\\tç–‘ä¼¼:" + str(data_dome['suspect']) + "\\næ­»äº¡:" + str(data_dome['dead']) + "\\tæ²»æ„ˆ:" + str(data_dome['heal'])
        text_prov = "\\n"

        text_dome = text_dome + "\\n\\nğŸ“°æœ€æ–°æ¶ˆæ¯ï¼š"
        for i in range(4):
            index = len(news) - 1 - i
            text_dome = text_dome + "\\n[" + news[index]['time'] + "]" + news[index]['title']

        data_prov_tree = data['areaTree'][0]['children']
        # output_log(data_prov_tree)
        for area_req in area_requested:
            prov_index = -1
            for i in range(len(data_prov_tree)):
                if data_prov_tree[i]['name'] == area_req:
                    output_log("äºç´¢å¼• " + str(i) + " è·å–åˆ°åˆ° " + area_req + "æ•°æ®ã€‚")
                    prov_index = i
                    break
            
            if i >= 0:
                data_prov = data_prov_tree[prov_index]
                # output_log(data_prov)
                text_prov = text_prov + "\\nğŸ™" + area_req + "æ•°æ®ï¼š\\nç¡®è¯Š:"
                text_prov = text_prov + str(data_prov['total']['confirm']) + "(+" + str(data_prov['today']['confirm']) + ")\\tç–‘ä¼¼:" + str(data_prov['total']['suspect']) + "(+" + str(data_prov['today']['suspect']) + ")\\næ­»äº¡:" + str(data_prov['total']['dead']) + "(+" + str(data_prov['today']['dead']) + ")\\t\\tæ²»æ„ˆ:" + str(data_prov['total']['heal']) + "(+" + str(data_prov['today']['heal']) + ")\\n"
                for city in data_prov['children']:
                    text_prov = text_prov + "â–ª" + city['name'] + "æ•°æ®:\\nç¡®è¯Š:" + str(city['total']['confirm']) + "(+" + str(city['today']['confirm']) + ")\\t\\tç–‘ä¼¼:" + str(city['total']['suspect']) + "(+" + str(city['today']['suspect']) + ")\\næ­»äº¡:" + str(city['total']['dead']) + "(+" + str(city['today']['dead']) + ")\\t\\tæ²»æ„ˆ:" + str(city['total']['heal']) + "(+" + str(city['today']['confirm']) + ")\\n"

        output_log("æ•°æ®è·å–æˆåŠŸï¼Œå‡†å¤‡æ¨é€è‡³IFTTTã€‚")
        IFTTT_push(text_dome, text_prov, False)
    except:
        try:
            IFTTT_push("æ•°æ®è·å–å¤±è´¥ã€‚", "è¯·æ‹¨å†—é€šçŸ¥æœåŠ¡è¿è¥è€…ã€‚", True)
            output_log("æ•°æ®è·å–å¤±è´¥ï¼è¯·æ£€æŸ¥ç¨‹åºï¼\n")
        except:
            output_log("æ•°æ®è·å–å¤±è´¥ï¼è¯·æ£€æŸ¥ç½‘è·¯ï¼\n")
    
    output_log("æœ¬è½®æ¨é€ç»“æŸã€‚")

def IFTTT_push(push_text_1, push_text_2, silent_mode):
    today    = datetime.date.today()
    CEE_left = (CEE_date - today).days

    push_val1_text = "2019-nCoV æ•°æ®æ¨é€\\næ¨é€æ—¶é—´ï¼š" + datetime.datetime.now().strftime("%Y-%m-%d %H:%M") + " GMT+8\\næ¨é€è®¾å¤‡ï¼š" + host_name + "\\né«˜è€ƒå€’è®¡æ—¶ï¼š" + str(CEE_left) + "å¤©\\næ¨é€å†…å®¹ï¼š"
    push_val2_text = "\\n" + push_text_1
    push_val3_text = "\\n" + push_text_2 + "\\n"
    body = "{ \"value1\": \"" + push_val1_text + "\", \"value2\": \"" + push_val2_text + "\", \"value3\": \"" + push_val3_text + "\" }"
    headers = { 'Content-Type': 'application/json' }

    try:
        for url in post_urls:
            requests.post(url, data = body.encode('utf-8'), headers = headers)
            if not silent_mode: output_log("å·²å®Œæˆå¯¹" + str(len(post_urls)) + "ä¸ªåœ°å€çš„æ¨é€ã€‚\n")
    except:
        output_log("æ¨é€å¤±è´¥ï¼Œè¯·æ£€æŸ¥è®¾ç½®ï¼\n")

def read_urls(path):
    return [t_url, ]
    a = pds.read_csv(path)
    names = a['event_name']
    keys  = a['key']
    urls  = [post_url_p1 + names[i] + post_url_p2 + keys[i] for i in range(len(names))]
    return urls

if __name__ == "__main__":    
    post_urls = read_urls(sub_doc_path)

    IFTTT_push("ç¨‹åºå·²ä¸Šçº¿ã€‚\\nå½“å‰ç‰ˆæœ¬ï¼š" + cur_version, "æ¨é€æ¨¡å¼ï¼šæ•´ç‚¹æ¨é€ã€‚\\n", True)

    output_log("ç¨‹åºå·²ä¸Šçº¿ã€‚å½“å‰ç‰ˆæœ¬ï¼š" + cur_version)
    output_log("å½“å‰è®¾å¤‡ Host Name: " + host_name + "\n")

    output_log("å¼€å§‹è¿è¡Œæ¨é€æœåŠ¡ã€‚æ¨é€æ¨¡å¼ï¼šæ•´ç‚¹æ¨é€ã€‚\n")
    get_data()
    scheduler = BlockingScheduler()
    trigger = CronTrigger(hour='*/1')
    scheduler.add_job(get_data,trigger)
    scheduler.start()